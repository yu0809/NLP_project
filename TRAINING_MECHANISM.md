# 训练机制说明

## 一、参数更新机制

### 关键点：参数更新**完全依赖 Loss**，不依赖 ROUGE 或 BERTScore

### 1. 训练过程中的参数更新

**参数更新使用的是交叉熵损失（Cross-Entropy Loss）**：

```python
# 在 Seq2SeqTrainer 中，默认使用交叉熵损失
# 损失函数计算的是预测token和真实token之间的交叉熵
loss = CrossEntropyLoss(predictions, labels)
```

**训练流程**：
1. 前向传播：模型生成预测
2. 计算损失：使用交叉熵损失函数
3. 反向传播：根据损失计算梯度
4. 参数更新：使用优化器（如Adam）更新参数

### 2. ROUGE 和 BERTScore 的作用

**ROUGE 和 BERTScore 仅用于评估和模型选择，不参与参数更新**：

```python
# 在训练代码中
metric_for_best_model="rougeL",  # 使用ROUGE-L选择最佳模型
compute_metrics=compute_metrics_wrapper,  # 计算ROUGE分数用于评估
```

**它们的作用**：
- ✅ **评估模型性能**：在验证集上计算ROUGE分数，了解模型效果
- ✅ **选择最佳模型**：训练过程中保存多个checkpoint，选择ROUGE-L最高的作为最佳模型
- ✅ **监控训练进度**：通过ROUGE分数判断模型是否在改进
- ❌ **不用于反向传播**：不参与梯度计算和参数更新

### 3. 为什么使用 Loss 而不是 ROUGE？

**技术原因**：
1. **可微性**：Loss（交叉熵）是可微的，可以进行反向传播
2. **ROUGE不可微**：ROUGE是基于n-gram匹配的离散指标，无法直接求导
3. **训练效率**：Loss计算快速，适合每个batch都计算
4. **标准做法**：这是序列生成任务的标准训练方式

**训练策略**：
- **训练时**：使用Loss进行参数更新（快速、可微）
- **评估时**：使用ROUGE评估性能（更符合任务目标）
- **选择时**：使用ROUGE-L选择最佳模型（更贴近实际应用）

### 4. 当前代码中的实现

```python
# train_with_hp_tuning.py 中的关键设置

training_args = Seq2SeqTrainingArguments(
    # ... 其他参数 ...
    load_best_model_at_end=True,  # 训练结束后加载最佳模型
    metric_for_best_model="rougeL",  # 使用ROUGE-L选择最佳模型
    greater_is_better=True,  # ROUGE分数越高越好
    predict_with_generate=True,  # 评估时生成完整序列（用于计算ROUGE）
)

# compute_metrics 函数只在评估时调用，不参与训练
def compute_metrics(eval_pred, tokenizer):
    # 计算ROUGE分数
    return {
        'rouge1': ...,
        'rouge2': ...,
        'rougeL': ...,
    }
```

### 5. 训练过程中的指标

**每个训练步骤**：
- Loss（交叉熵）：用于参数更新
- 训练速度：tokens/秒

**每个评估步骤**：
- Loss（交叉熵）：验证集上的损失
- ROUGE-1：基于unigram的重叠度
- ROUGE-2：基于bigram的重叠度
- ROUGE-L：基于最长公共子序列的分数

**注意**：在 `test_pretrained.py` 中**已添加BERTScore评估**，用于最终测试阶段的性能评估。

## 二、test_pretrained.py 输出内容说明

### 运行命令

```bash
# 测试所有模型
python test_pretrained.py

# 测试单个模型
python test_pretrained.py --model_key 1

# 限制测试样本数
python test_pretrained.py --max_samples 100
```

### 输出内容示例

#### 1. 测试单个模型时的输出

```
================================================================================
测试预训练模型: google/mt5-base
描述: mT5-base - 基础模型，平衡性能和速度（推荐）
================================================================================

正在加载预训练模型...
正在加载模型: google/mt5-base
使用设备: cpu
模型加载完成！

加载测试数据: Pre LCSTS/test.csv
测试样本数: 1103

开始评估...
--------------------------------------------------------------------------------
处理进度: 10/1103
处理进度: 20/1103
处理进度: 30/1103
...
处理进度: 1100/1103

================================================================================
评估结果
================================================================================
模型: google/mt5-base
ROUGE-1: 0.3245
ROUGE-2: 0.1567
ROUGE-L: 0.2989
测试样本数: 1103
================================================================================
```

#### 2. 测试所有模型时的输出

```
================================================================================
测试所有预训练模型（不微调）
================================================================================

================================================================================
测试预训练模型: google/mt5-base
描述: mT5-base - 基础模型，平衡性能和速度（推荐）
================================================================================

正在加载预训练模型...
[模型加载过程...]

加载测试数据: Pre LCSTS/test.csv
测试样本数: 1103

开始评估...
[评估过程...]

================================================================================
评估结果
================================================================================
模型: google/mt5-base
ROUGE-1: 0.3245
ROUGE-2: 0.1567
ROUGE-L: 0.2989
测试样本数: 1103
================================================================================


================================================================================
测试预训练模型: facebook/mbart-large-cc25
描述: mBART-large - 多语言BART模型，支持中文
================================================================================

[模型2的测试过程...]


================================================================================
测试预训练模型: csebuetnlp/mT5_multilingual_XLSum
描述: mT5 XLSum - 专门用于摘要任务的多语言模型
================================================================================

[模型3的测试过程...]


================================================================================
测试结果汇总
================================================================================

模型                                      ROUGE-1      ROUGE-2      ROUGE-L     
--------------------------------------------------------------------------------
mT5_multilingual_XLSum                   0.3456       0.1678       0.3123     
mt5-base                                 0.3245       0.1567       0.2989     
mbart-large-cc25                         0.3102       0.1456       0.2856     

详细结果已保存到: pretrained_test_results.json
================================================================================
```

### 输出内容详解

#### 1. 模型信息
- 模型名称（如 `google/mt5-base`）
- 模型描述
- 使用的设备（CPU或GPU）

#### 2. 数据信息
- 测试文件路径
- 测试样本数量

#### 3. 评估过程
- 实时显示处理进度（每10个样本显示一次）
- 如果某个样本处理失败，会显示错误信息

#### 4. 评估结果
- **ROUGE-1**：基于unigram的重叠度，衡量单词级别的匹配
- **ROUGE-2**：基于bigram的重叠度，衡量短语级别的匹配
- **ROUGE-L**：基于最长公共子序列，衡量句子级别的匹配
- 测试样本数：成功处理的样本数量

#### 5. 结果汇总（测试所有模型时）
- 按ROUGE-L分数从高到低排序
- 以表格形式展示所有模型的性能对比

### 保存的文件

**pretrained_test_results.json** 包含：
```json
[
  {
    "model_key": "1",
    "model_name": "google/mt5-base",
    "description": "mT5-base - 基础模型，平衡性能和速度（推荐）",
    "rouge1": 0.3245,
    "rouge2": 0.1567,
    "rougeL": 0.2989,
    "num_samples": 1103,
    "test_file": "Pre LCSTS/test.csv",
    "timestamp": "2024-01-01T12:00:00"
  },
  {
    "model_key": "2",
    "model_name": "facebook/mbart-large-cc25",
    ...
  },
  ...
]
```

### 指标说明

**ROUGE分数范围**：0.0 - 1.0，越高越好

- **ROUGE-1 > 0.3**：表示模型生成的摘要与参考摘要有30%以上的单词重叠
- **ROUGE-2 > 0.15**：表示模型生成的摘要与参考摘要有15%以上的短语重叠
- **ROUGE-L > 0.3**：表示模型生成的摘要与参考摘要在句子结构上有30%以上的相似度

**典型值**：
- 预训练模型（不微调）：ROUGE-L 通常在 0.25-0.35 之间
- 微调后的模型：ROUGE-L 通常在 0.35-0.50 之间

## 三、总结

### 训练机制
- ✅ **参数更新**：使用交叉熵Loss
- ✅ **模型选择**：使用ROUGE-L选择最佳checkpoint
- ✅ **性能评估**：使用ROUGE-1/2/L评估模型效果
- ❌ **不使用BERTScore**：当前代码未实现BERTScore评估

### 测试脚本输出
- 显示模型加载过程
- 显示评估进度
- 显示ROUGE分数（1/2/L）
- **显示BERTScore分数（Precision/Recall/F1）**
- 保存详细结果到JSON文件
- 提供模型性能对比表格（ROUGE和BERTScore分别展示）

